{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Run Locally (Windows)\n\n```powershell\n$env:PYTHONPATH = \"$PWD\"\njupyter notebook\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 1. Purpose\n\n**What Shifts:**\n- From: M4.1 \u2014 Model Cards & AI Governance\n- To: M4.2 \u2014 Vendor Risk Assessment\n\n**Why This Bridge Matters:**\nM4.1 established your internal AI governance infrastructure (model documentation, bias detection, HITL systems, governance committees). Now you need to extend governance **outward** to evaluate third-party vendors in your RAG stack. M4.2 introduces systematic vendor evaluation frameworks to assess security, privacy, compliance, and reliability of external dependencies like OpenAI, Pinecone, AWS, and Datadog.\n\n**Bridge Type:** Readiness Validation"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 2. Concepts Covered\n\n**New Concepts in M4.2:**\n- **Vendor Evaluation Matrix** \u2014 5-category weighted scoring system for systematic vendor assessment\n- **Security Risk Scoring** \u2014 SOC 2 compliance, penetration testing, incident history assessment\n- **Privacy Risk Scoring** \u2014 GDPR compliance, data handling practices, subprocessor management\n- **Compliance Category Scoring** \u2014 Certifications, regulatory alignment, audit trail maintenance\n- **Reliability Metrics** \u2014 Uptime SLA tracking, disaster recovery capabilities, support responsiveness\n- **Data Residency Assessment** \u2014 Multi-region support, jurisdiction compliance verification\n- **Automated DPA Review Tool** \u2014 Validates 12 essential GDPR Article 28 clauses in Data Processing Agreements\n- **Subprocessor Registry** \u2014 Tracks vendor dependency chains and vendor-of-vendor relationships\n- **Continuous Vendor Monitoring** \u2014 Automated tracking of certification expiration, uptime, incidents, term changes\n\n**Building On:**\n- M4.1 established: Internal governance (model cards, bias detection, HITL, committees)\n- M4.2 extends: External governance (vendor evaluation, DPA review, continuous monitoring)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 3. After Completing This Bridge\n\n**You Will Be Able To:**\n- \u2713 Verify completion of M4.1 internal governance artifacts (model cards, governance docs)\n- \u2713 Confirm understanding of governance frameworks (NIST AI RMF, EU AI Act)\n- \u2713 Validate environment readiness for vendor risk assessment workflows\n- \u2713 Identify gaps between internal governance and external vendor evaluation needs\n\n**Pass Criteria:**\n- All 4 checks pass (\u2713)\n- No critical gaps (\u2717)\n- Ready for M4.2 content (vendor evaluation frameworks)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## 4. Context in Track\n\n**Position:** Bridge L3.M4.1 \u2192 L3.M4.2\n\n**Learning Journey:**\n```\nL3.M4.1 \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500[THIS BRIDGE]\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2192 L3.M4.2\nInternal Governance    Validation    Vendor Risk Assessment\n(Model Cards, HITL)                  (Vendor Eval, DPA Review)\n```\n\n**Time Estimate:** 15-30 minutes"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Recap: What You Built in M4.1\n\nIn M4.1, you established comprehensive **internal AI governance infrastructure** for your RAG systems:\n\n**Key Deliverables:**\n- **Model Card System** \u2014 Documented model metadata, performance metrics, bias assessment, and intended use cases\n- **Bias Detection Pipeline** \u2014 Implemented demographic parity checks, equalized odds testing, and fairness metrics\n- **Human-in-the-Loop (HITL) Workflows** \u2014 Built review queues for low-confidence predictions with PostgreSQL-backed task management\n- **Governance Committee Structure** \u2014 Established cross-functional oversight (Legal, Engineering, Product, Compliance)\n- **Compliance Framework Alignment** \u2014 Mapped controls to NIST AI Risk Management Framework and EU AI Act requirements\n\n**What This Means:**\nYou now have internal controls for **your own AI systems**. M4.2 extends this governance to **third-party vendors** powering your RAG stack (LLMs, vector databases, cloud infrastructure)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Readiness Check #1: Model Card Artifacts\n\n**What This Validates:** Completion of M4.1 model documentation system\n\n**Pass Criteria:**\n- \u2713 Model card file exists in expected location\n- \u2713 Card contains required sections (metadata, performance, bias assessment, intended use)\n- \u2713 Bias metrics are documented\n- \u2713 Governance approval is recorded"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Check #1: Model Card Artifacts\nfrom pathlib import Path\nimport json\n\nmodel_card_path = Path(\"model_cards/rag_model_card.json\")\nrequired_sections = [\"metadata\", \"performance\", \"bias_assessment\", \"intended_use\"]\n\nif not model_card_path.exists():\n    print(f\"\u2717 Check #1 FAILED: Missing model card\")\n    print(f\"   Expected: {model_card_path}\")\n    print(f\"   Fix: Complete M4.1 model card exercise\")\nelse:\n    with open(model_card_path) as f:\n        card_data = json.load(f)\n    \n    missing = [s for s in required_sections if s not in card_data]\n    if missing:\n        print(f\"\u2717 Check #1 FAILED: Missing sections {missing}\")\n    else:\n        print(\"\u2713 Check #1 PASSED: Model card complete\")\n\n# Expected: \u2713 Check #1 PASSED: Model card complete",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Readiness Check #2: Governance Framework Documentation\n\n**What This Validates:** Governance committee structure and compliance framework from M4.1\n\n**Pass Criteria:**\n- \u2713 Governance committee charter exists\n- \u2713 Committee includes cross-functional roles (Legal, Engineering, Product, Compliance)\n- \u2713 NIST AI RMF mapping document exists\n- \u2713 EU AI Act alignment document exists"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Check #2: Governance Framework Documentation\nfrom pathlib import Path\n\nrequired_docs = {\n    \"governance/committee_charter.md\": \"Governance committee charter\",\n    \"governance/nist_ai_rmf_mapping.md\": \"NIST AI RMF mapping\",\n    \"governance/eu_ai_act_alignment.md\": \"EU AI Act alignment\"\n}\n\nall_passed = True\nfor doc_path, doc_name in required_docs.items():\n    if not Path(doc_path).exists():\n        print(f\"\u2717 Missing: {doc_name}\")\n        print(f\"   Expected: {doc_path}\")\n        all_passed = False\n\nif all_passed:\n    print(\"\u2713 Check #2 PASSED: Governance framework complete\")\nelse:\n    print(\"\\n\u2717 Check #2 FAILED\")\n    print(\"   Fix: Complete M4.1 governance documentation\")\n\n# Expected: \u2713 Check #2 PASSED: Governance framework complete",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Readiness Check #3: Conceptual Understanding\n\n**What This Validates:** Understanding of M4.1 governance concepts before extending to vendors\n\n**Pass Criteria:**\n- \u2713 Can explain purpose of model cards\n- \u2713 Can describe bias detection metrics (demographic parity, equalized odds)\n- \u2713 Can explain HITL workflow components\n- \u2713 Can articulate difference between NIST AI RMF and EU AI Act"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Check #3: Conceptual Understanding\nreadiness_questions = [\n    \"Q1: What sections must a model card include for AI governance?\",\n    \"Q2: What is demographic parity in bias detection?\",\n    \"Q3: What triggers a prediction to enter the HITL review queue?\",\n    \"Q4: How does NIST AI RMF differ from EU AI Act requirements?\",\n]\n\nprint(\"Verify your M4.1 understanding by answering these:\\n\")\nfor q in readiness_questions:\n    print(f\"   {q}\")\n\nprint(\"\\n\u2713 Check #3 PASSED if you can clearly answer all questions\")\nprint(\"\\n\u2717 If uncertain, review M4.1 conceptual materials before M4.2\")\n\n# Expected: Clear answers to all 4 questions\n# Example answers:\n# Q1: metadata, performance, bias_assessment, intended_use, limitations\n# Q2: Equal positive outcome rates across demographic groups\n# Q3: Confidence score below threshold (e.g., <0.75)\n# Q4: NIST = risk management framework; EU AI Act = regulatory requirements",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Readiness Check #4: Environment Setup for M4.2\n\n**What This Validates:** Python environment is ready for vendor risk assessment tools\n\n**Pass Criteria:**\n- \u2713 Python 3.9+ installed\n- \u2713 Required packages available (pandas, requests, json)\n- \u2713 Jupyter environment functional\n- \u2713 File I/O permissions verified"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Check #4: Environment Setup\nimport sys\nfrom pathlib import Path\n\nprint(f\"Python version: {sys.version}\")\n\nrequired_packages = [\"pandas\", \"json\", \"pathlib\"]\nall_available = True\n\nfor pkg in required_packages:\n    try:\n        __import__(pkg)\n        print(f\"\u2713 {pkg} available\")\n    except ImportError:\n        print(f\"\u2717 {pkg} missing\")\n        print(f\"   Fix: pip install {pkg}\")\n        all_available = False\n\n# Test file I/O\ntest_file = Path(\"test_write.tmp\")\ntest_file.write_text(\"test\")\ntest_file.unlink()\nprint(\"\u2713 File I/O functional\")\n\nif all_available:\n    print(\"\\n\u2713 Check #4 PASSED: Environment ready for M4.2\")\n\n# Expected: \u2713 Check #4 PASSED: Environment ready for M4.2",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Call-Forward: What's Next in M4.2\n\n**Module M4.2 Will Cover:**\n\n**1. Vendor Evaluation Matrix**\n- Weighted scoring across 5 categories: Security (30%), Privacy (25%), Compliance (20%), Reliability (15%), Data Residency (10%)\n- Assess vendors like OpenAI, Pinecone, AWS, Datadog against enterprise risk criteria\n- Generate executive-ready risk scores for vendor approval decisions\n\n**2. Automated DPA Review Tool**\n- Validate 12 essential GDPR Article 28 clauses in Data Processing Agreements\n- Check for: subprocessor approval, data deletion procedures, security measures, breach notification timelines, audit rights\n- Flag missing or non-compliant clauses automatically\n\n**3. Subprocessor Tracking System**\n- Map complete vendor dependency chains (vendor-of-vendor relationships)\n- Alert on unauthorized subprocessor additions\n- Maintain compliance documentation for audit trails\n\n**4. Continuous Vendor Monitoring Dashboard**\n- Track SOC 2 certification expiration dates\n- Monitor uptime SLA compliance\n- Alert on security incidents and compliance changes\n- Detect Terms of Service modifications affecting data handling\n\n---\n\n**Why You're Ready:**\n- \u2713 You understand internal governance (M4.1 model cards, bias detection, HITL)\n- \u2713 You recognize governance extends beyond your own systems to third-party vendors\n- \u2713 You have the conceptual foundation to evaluate external risk systematically\n\n**What to Expect:**\n- **Duration:** 2-3 hours (hands-on vendor evaluation exercises)\n- **Complexity:** Intermediate (scoring frameworks, DPA parsing, monitoring automation)\n- **Key Deliverables:**\n  - Vendor risk scorecard for your RAG stack vendors\n  - DPA compliance report\n  - Subprocessor registry\n  - Monitoring dashboard prototype\n\n---\n\n**If You're Not Ready:**\n- Review M4.1 materials (model cards, governance frameworks)\n- Complete failed checks above\n- Reach out for support: support@techvoyagehub.com\n\n**Next Steps:**\n1. Ensure ALL 4 checks passed (\u2713)\n2. Proceed to **M4.2: Vendor Risk Assessment**\n3. Reference this bridge if you need to validate M4.1 prerequisites"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}